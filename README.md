# Job Recommendation System ğŸ’¼ğŸ”

Ce projet est un systÃ¨me de recommandation d'emplois basÃ© sur le traitement du langage naturel (NLP). Il analyse le CV de l'utilisateur et recommande les 20 meilleurs emplois alignÃ©s avec son profil. Les offres d'emploi sont extraites de LinkedIn et Indeed. De plus, l'utilisateur peut gÃ©nÃ©rer une lettre de motivation pour une offre spÃ©cifique et obtenir des statistiques dÃ©taillÃ©es sur les compÃ©tences techniques et les langages les plus demandÃ©s.
![image](https://github.com/user-attachments/assets/e9689be7-eabf-42a6-b4c7-0a20ed36c8fd)

---

## FonctionnalitÃ©s âœ¨

1. **Recommandation d'emplois** ğŸ“:
   - L'utilisateur tÃ©lÃ©charge son CV (format PDF ou DOCX).
   - Le systÃ¨me analyse le CV et recommande les 20 meilleurs emplois alignÃ©s avec son profil.

2. **GÃ©nÃ©ration de lettre de motivation** ğŸ’Œ:
   - L'utilisateur peut fournir l'URL d'une offre d'emploi.
   - Le systÃ¨me gÃ©nÃ¨re une lettre de motivation personnalisÃ©e pour cette offre.

3. **Statistiques et insights** ğŸ“Š:
   - Analyse des compÃ©tences techniques et des langages les plus demandÃ©s dans les offres d'emploi.
   - Statistiques sur les localisations et les titres de poste les plus populaires.
   - Visualisation des compÃ©tences techniques et des soft skills les plus recherchÃ©s.

## ğŸ“‚ Structure du Projet

```plaintext
Job_recommendation_System/
â”œâ”€â”€ Webscrapping/                                                           # Scripts de web scraping pour LinkedIn, Indeed et Glassdoor
â”‚ â”œâ”€â”€ chromedriver.exe                                                      # Pilote Chrome pour Selenium
â”‚ â”œâ”€â”€ glassdoor_refactor.ipynb                                              # Notebook pour le scraping de Glassdoor
â”‚ â”œâ”€â”€ indeed_refactor.ipynb                                                 # Notebook pour le scraping de Indeed
â”‚ â”œâ”€â”€ linkedin_refactor.ipynb                                               # Notebook pour le scraping de LinkedIn
â”‚ â””â”€â”€ pass_linkedin.txt                                                     # Fichier contenant les identifiants LinkedIn
â”œâ”€â”€ data/                                                                   # Dossier contenant les donnÃ©es brutes et traitÃ©es
â”‚ â”œâ”€â”€ data_full_translate_to_en_de_23_2907_drop_duplicates.csv              # DonnÃ©es traduites et nettoyÃ©es
â”‚ â”œâ”€â”€ skill_extraction_Skiller_03.08_final.csv                              # Extraction des compÃ©tences
â”‚ â”œâ”€â”€ skill_extraction_Skiller_03.08_final_web.csv                          # Extraction des compÃ©tences (web)
â”‚ â”œâ”€â”€ skill_extraction_Skiller_03.08_final_web_v1.csv                       # Extraction des compÃ©tences (web v1)
â”‚ â”œâ”€â”€ skill_extraction_Skiller_08.08_final_web.csv                          # Extraction des compÃ©tences (web finale)
â”‚ â””â”€â”€ skill_name.csv                                                        # Liste des compÃ©tences
â”œâ”€â”€ data_exploratory/                                                       # Notebooks pour l'exploration et le nettoyage des donnÃ©es
â”‚ â”œâ”€â”€ data_cleaning.ipynb                                                   # Nettoyage des donnÃ©es
â”‚ â””â”€â”€ data_exploratory.ipynb                                                # Exploration des donnÃ©es
â”œâ”€â”€ model/                                                                  # ModÃ¨les de machine learning et NLP
â”‚ â”œâ”€â”€ als_model.pkl                                                         # ModÃ¨le ALS pour la recommandation
â”‚ â”œâ”€â”€ skill_extractor.pkl                                                   # ModÃ¨le d'extraction des compÃ©tences
â”‚ â”œâ”€â”€ skill_extractor_sm.pkl                                                # ModÃ¨le d'extraction des compÃ©tences (version light)
â”‚ â”œâ”€â”€ tfidf_model.pkl                                                       # ModÃ¨le TF-IDF
â”‚ â””â”€â”€ tfidf_model_0808.pkl                                                  # ModÃ¨le TF-IDF mis Ã  jour
â”œâ”€â”€ picture/                                                                # Dossier contenant les images utilisÃ©es dans l'application
â”œâ”€â”€ ultility/                                                               # Scripts utilitaires
â”‚ â”œâ”€â”€ cleaning.py                                                           # Fonctions de nettoyage des donnÃ©es
â”‚ â””â”€â”€ language.py                                                           # Fonctions de traitement du langage
â”œâ”€â”€ README.md                                                               # Fichier README
â”œâ”€â”€ about.py                                                                # Page "Ã€ propos" de l'application
â”œâ”€â”€ app.py                                                                  # Point d'entrÃ©e de l'application
â”œâ”€â”€ cover_letter.py                                                         # GÃ©nÃ©ration de lettres de motivation
â”œâ”€â”€ home.py                                                                 # Page d'accueil de l'application
â”œâ”€â”€ job_recommender.py                                                      # SystÃ¨me de recommandation d'emplois
â”œâ”€â”€ page_statistics.py                                                      # Page des statistiques et insights
â””â”€â”€ requirements.txt                                                        # DÃ©pendances du projet
```

---

## Technologies utilisÃ©es ğŸ’»

- **Langages** : Python
- **Frameworks** : Streamlit (interface utilisateur)
- **Traitement de texte** : spaCy, NLTK, PyPDF2 (pour l'analyse de CV)
- **Web scraping** : BeautifulSoup, Selenium (pour extraire les offres d'emploi)
- **Machine Learning** : Scikit-learn, TensorFlow (pour la recommandation)
- **Visualisation** : Matplotlib, Seaborn, Plotly (pour les statistiques)
- **GÃ©nÃ©ration de texte** : OpenAI GPT (pour les lettres de motivation)

---

## Ã‰tapes dÃ©taillÃ©es du projet ğŸ”

### 1. **Web Scraping**
   - **Objectif** : Extraire les offres d'emploi de LinkedIn, Indeed et Glassdoor.
   - **Outils** : Selenium, BeautifulSoup.
   - **Processus** :
     1. **Configuration de Selenium** : Utilisation de `chromedriver.exe` pour automatiser la navigation sur les sites web.
     2. **Connexion aux sites** : Les identifiants LinkedIn sont stockÃ©s dans `pass_linkedin.txt` pour une connexion automatisÃ©e.
     3. **Extraction des donnÃ©es** : Les offres d'emploi sont extraites en parcourant les pages web et en rÃ©cupÃ©rant les informations clÃ©s (titre, description, localisation, etc.).
     4. **Sauvegarde des donnÃ©es** : Les donnÃ©es extraites sont sauvegardÃ©es dans des fichiers CSV pour un traitement ultÃ©rieur.

### 2. **Data Cleaning**
   - **Objectif** : Nettoyer les donnÃ©es brutes pour les rendre utilisables.
   - **Outils** : Pandas, NumPy.
   - **Processus** :
     1. **Suppression des doublons** : Les offres d'emploi en double sont supprimÃ©es.
     2. **Traitement des valeurs manquantes** : Les champs vides sont remplis ou supprimÃ©s.
     3. **Normalisation des donnÃ©es** : Les textes sont convertis en minuscules, les caractÃ¨res spÃ©ciaux sont supprimÃ©s, et les formats de date sont standardisÃ©s.
     4. **Traduction des donnÃ©es** : Les offres d'emploi sont traduites en anglais pour une analyse cohÃ©rente.

### 3. **Data Exploration**
   - **Objectif** : Explorer les donnÃ©es pour identifier des tendances et des insights.
   - **Outils** : Pandas, Matplotlib, Seaborn.
   - **Processus** :
     1. **Analyse des compÃ©tences** : Les compÃ©tences techniques les plus demandÃ©es sont identifiÃ©es.
     2. **Visualisation des donnÃ©es** : Des graphiques sont gÃ©nÃ©rÃ©s pour montrer les tendances des offres d'emploi par localisation, titre de poste et compÃ©tences.
     3. **Extraction des insights** : Les insights sont utilisÃ©s pour amÃ©liorer le systÃ¨me de recommandation.

### 4. **Traitement du Langage Naturel (NLP)**
   - **Objectif** : Analyser les textes des offres d'emploi et des CV pour extraire des informations clÃ©s.
   - **Outils** : spaCy, NLTK, PyPDF2.
   - **Processus** :
     1. **Tokenisation** : Les textes sont divisÃ©s en mots ou phrases.
     2. **Lemmatisation** : Les mots sont rÃ©duits Ã  leur forme de base (par exemple, "running" devient "run").
     3. **Suppression des stop words** : Les mots courants (comme "le", "de", "et") sont supprimÃ©s.
     4. **Extraction des entitÃ©s nommÃ©es** : Les noms, lieux, dates et autres entitÃ©s sont extraits.

### 5. **Extraction des CompÃ©tences**
   - **Objectif** : Identifier les compÃ©tences techniques et les soft skills dans les offres d'emploi et les CV.
   - **Outils** : spaCy, Scikit-learn.
   - **Processus** :
     1. **CrÃ©ation d'un corpus de compÃ©tences** : Une liste de compÃ©tences techniques et de soft skills est crÃ©Ã©e Ã  partir des donnÃ©es disponibles.
     2. **Matching des compÃ©tences** : Les compÃ©tences sont identifiÃ©es dans les textes en utilisant des techniques de matching de mots-clÃ©s.
     3. **ModÃ©lisation** : Un modÃ¨le TF-IDF est utilisÃ© pour pondÃ©rer l'importance des compÃ©tences dans les offres d'emploi.

### 6. **CrÃ©ation du Corpus**
   - **Objectif** : Construire un corpus de textes pour entraÃ®ner les modÃ¨les NLP.
   - **Outils** : spaCy, NLTK.
   - **Processus** :
     1. **Collecte des textes** : Les descriptions d'offres d'emploi et les CV sont collectÃ©s.
     2. **PrÃ©traitement des textes** : Les textes sont nettoyÃ©s et normalisÃ©s.
     3. **CrÃ©ation du corpus** : Les textes sont organisÃ©s en un corpus structurÃ© pour l'analyse et la modÃ©lisation.

---

## Installation ğŸ› ï¸

### 1. **Cloner le dÃ©pÃ´t**
   ```bash
   git clone https://github.com/Meriam-Inoubli/Job_recommendation_System.git
   ```
### 2. **AccÃ©der au dossier du projet**
   ```bash
   cd Job_recommendation_System
   ```
### 3. **CrÃ©er un environnement virtuel (optionnel mais recommandÃ©)**
   ```bash
   python -m venv env
   source env/bin/activate  # Sur Windows : env\Scripts\activate
   ```
### 4. **Installer les dÃ©pendances**
   ```bash
   pip install -r requirements.txt
   ```
## Utilisation ğŸš€
### 1. **Lancer l'application Streamlit**
   ```bash
   streamlit run app.py
   ```
### 2. **Ouvrir l'application dans le navigateur**
L'application sera accessible Ã  l'adresse suivante : http://localhost:8501.

### 3. **TÃ©lÃ©charger votre CV**
Sur la page d'accueil, tÃ©lÃ©chargez votre CV au format PDF ou DOCX.

### 4. **Obtenir les recommandations d'emplois**
Le systÃ¨me analysera votre CV et affichera les 20 meilleurs emplois alignÃ©s avec votre profil.

### 5. **GÃ©nÃ©rer une lettre de motivation**
Entrez l'URL d'une offre d'emploi.
Le systÃ¨me gÃ©nÃ©rera une lettre de motivation personnalisÃ©e basÃ©e sur votre CV et les dÃ©tails de l'offre.

### 6. **Explorer les statistiques**
Consultez les statistiques sur les compÃ©tences techniques, les langages de programmation, les localisations et les titres de poste les plus demandÃ©s.

## Auteur ğŸ‘©â€ğŸ’»
Meriam Inoubli : meriam.inoubli@dauphine.tn
Ferdaws Ziadia : ferdaws.ziadia@dauphine.tn

## Licence ğŸ“œ
Ce projet est sous licence MIT. Voir le fichier LICENSE pour plus de dÃ©tails.

